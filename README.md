# Python for Data Analysis
Exploring and visualizing insights in the data jobs market.

<p align="center">
  <img src="https://i.imgur.com/zcpIFfp.jpeg" alt="Title" width="840px" height="120px">
</p>


## Description and getting started
This repository is dedicated to exploring and visualizing insights in the data jobs market. The primary focus of the project is to leverage Python libraries such as NumPy, Pandas, Matplotlib and Seaborn for data analysis and visualization. The dataset used for this project is "Jobs and Salaries in Data Science," created by Hummaam Qaasim and available on Kaggle

The repository likely includes the necessary scripts, data files, and instructions to run the project locally. Interested users can explore the codebase, run the scripts, and potentially contribute to the ongoing efforts to improve Matplotlib graphs. The key metrics that you can utilize in this .cvs are: work year, job title, job category, salary (included currency, salary and salary in USD), employee residence, experience level, employment type, work setting (in person, remote or hybrid), company location and company size (L for large, M for medium and S for small)

Won't spoil much but can say that the average salary is around the $150.000 mark, "Data Science and Research" seems to be the most abundant job category (32.2%), and if we look at average salaries the U.S. comes 4th, just behind Qatar, Puerto Rico and Japan.

### 1. datajobs.py:
* I applied VERY basic Matplotlib and Seaborn use since I was just trying and learning my first steps towards this two libraries
* This module is primarily directed towards the graphic design aspect of NumPy, Pandas, and Matplotlib libraries
* It is responsible for creating graphical representations of various aspects of the dataset, such as salary distributions, job categories breakdowns, and geographical distribution of data jobs

### 2. numpypandas.py and morepandas.py:
* These modules are focused on applying knowledge about Pandas.
* The functionalities implemented in these modules involve data manipulation and analysis using Pandas, showcasing the versatility of the library

### 3. snspractice.py:
* Here I focused mostly on Seaborn and what this librarie really offers. Went through documentation and videos to understand it and this module is some of the exercises I did to test and improve my understanding of it, for this module I did not use the dataset mentioned above but the ones that the library offers as default (tips, iris and titanic)

Here we have what I started doing during my first steps (datajobs.py) vs what I got to do after some experimentation (snspractice.py)
<p align="center">
  <img src="https://i.imgur.com/NOPf3vK.png" alt="Before vs After" width="650px" height="340px">
</p>

### 4. 3d.py:
* Thanks to matplotlib I got to create 3d graphics that I find interesting and that will further explore since I find them really useful for data driven story-telling

  <p align="center">
  <img src="https://i.imgur.com/dxgdu5O.png" alt="Title" width="650px" height="170px">
</p>


## What I Learned
The project served as an opportunity for me to expand and master the libraries NumPy, Pandas, Matplotlib and Seaborn. Applied knowledge includes handling data with Pandas, performing operations with NumPy, and creating informative visualizations with Matplotlib/Seaborn. Also learned about a bunch new of ways of creating visually appealing graphics including 3D models where you can freely move around.

## What's next
I want to keep improving my data visualization skills while maintaining them clean and informative, so I will keep digging the Matplotlib and Seaborn documentation + going through tutorials to further improve my dexterity using both libraries

